{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (0.12.23)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.23 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.12.23.post2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.6.8)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.3.25)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.66.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.23->llama_index) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (2025.3.0)\n",
      "Requirement already satisfied: httpx in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.23->llama_index) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.14)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.13.3)\n",
      "Requirement already satisfied: pandas in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.4.post1)\n",
      "Requirement already satisfied: click in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.23->llama_index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.23->llama_index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.23->llama_index) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.23->llama_index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.23->llama_index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.23->llama_index) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.23->llama_index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.6)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.23->llama_index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.23->llama_index) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.23->llama_index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.23->llama_index) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.4 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.23->llama_index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.23->llama_index) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.23->llama_index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.23->llama_index) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.23->llama_index) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.23->llama_index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.23->llama_index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.23->llama_index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (1.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.23->llama_index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.2-py3-none-any.whl.metadata (767 bytes)\n",
      "Collecting huggingface-hub>=0.19.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-embeddings-huggingface) (0.12.23.post2)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Using cached sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.13)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.39)\n",
      "Requirement already satisfied: dataclasses-json in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.5.2-py3-none-any.whl (8.9 kB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Using cached torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, setuptools, scipy, safetensors, MarkupSafe, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.17.0 huggingface-hub-0.29.3 jinja2-3.1.6 llama-index-embeddings-huggingface-0.5.2 mpmath-1.3.0 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-3.4.1 setuptools-76.0.0 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 transformers-4.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-embeddings-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-qdrant\n",
      "  Using cached llama_index_vector_stores_qdrant-0.1.4-py3-none-any.whl.metadata (696 bytes)\n",
      "Collecting grpcio<2.0.0,>=1.60.0 (from llama-index-vector-stores-qdrant)\n",
      "  Using cached grpcio-1.71.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-vector-stores-qdrant)\n",
      "  Downloading llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting qdrant-client<2.0.0,>=1.7.1 (from llama-index-vector-stores-qdrant)\n",
      "  Downloading qdrant_client-1.13.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2025.3.0)\n",
      "Requirement already satisfied: httpx in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.4.2)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.9.1)\n",
      "Collecting numpy<2.0.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-win_amd64.whl\n",
      "Requirement already satisfied: pandas in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (11.1.0)\n",
      "Requirement already satisfied: pydantic<3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.17.2)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant)\n",
      "  Downloading grpcio_tools-1.71.0-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "INFO: pip is looking at multiple versions of qdrant-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting qdrant-client<2.0.0,>=1.7.1 (from llama-index-vector-stores-qdrant)\n",
      "  Using cached qdrant_client-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading qdrant_client-1.13.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading qdrant_client-1.13.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading qdrant_client-1.12.2-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading qdrant_client-1.12.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (2.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.18.3)\n",
      "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant)\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (76.0.0)\n",
      "Requirement already satisfied: anyio in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.14.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant)\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: click in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.11.6)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (309)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2025.1)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.3.1)\n",
      "Downloading llama_index_vector_stores_qdrant-0.1.4-py3-none-any.whl (8.6 kB)\n",
      "Using cached grpcio-1.71.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "Downloading llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.6 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 766.7 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.0/1.6 MB 916.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 887.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 919.6 kB/s eta 0:00:00\n",
      "Downloading qdrant_client-1.12.1-py3-none-any.whl (267 kB)\n",
      "Downloading grpcio_tools-1.71.0-cp313-cp313-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.3/1.1 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 0.8/1.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.0/1.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 1.2 MB/s eta 0:00:00\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: tenacity, protobuf, portalocker, numpy, hyperframe, hpack, grpcio, h2, grpcio-tools, llama-index-core, qdrant-client, llama-index-vector-stores-qdrant\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.12.23.post2\n",
      "    Uninstalling llama-index-core-0.12.23.post2:\n",
      "      Successfully uninstalled llama-index-core-0.12.23.post2\n",
      "Successfully installed grpcio-1.71.0 grpcio-tools-1.71.0 h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 llama-index-core-0.10.68.post1 llama-index-vector-stores-qdrant-0.1.4 numpy-1.26.4 portalocker-2.10.1 protobuf-5.29.3 qdrant-client-1.12.1 tenacity-8.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-cloud-services 0.6.5 requires llama-index-core>=0.11.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index 0.12.23 requires llama-index-core<0.13.0,>=0.12.23, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-agent-openai 0.4.6 requires llama-index-core<0.13.0,>=0.12.18, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-cli 0.4.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-embeddings-huggingface 0.5.2 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-embeddings-openai 0.3.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.6.8 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-llms-openai 0.3.25 requires llama-index-core<0.13.0,>=0.12.17, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.4.3 requires llama-index-core<0.13.0,>=0.12.3, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-program-openai 0.3.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-question-gen-openai 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-readers-file 0.4.6 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.4.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-qdrant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-gemini\n",
      "  Using cached llama_index_llms_gemini-0.4.11-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting google-generativeai>=0.5.2 (from llama-index-llms-gemini)\n",
      "  Using cached google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.12 (from llama-index-llms-gemini)\n",
      "  Using cached llama_index_core-0.12.23.post2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pillow<11.0.0,>=10.2.0 (from llama-index-llms-gemini)\n",
      "  Downloading pillow-10.4.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Downloading google_api_python_client-2.164.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: protobuf in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.10.6)\n",
      "Requirement already satisfied: tqdm in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2025.3.0)\n",
      "Requirement already satisfied: httpx in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.18.3)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: click in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from tqdm->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (3.26.1)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (0.14.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.71.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (24.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.12->llama-index-llms-gemini) (1.3.1)\n",
      "Downloading llama_index_llms_gemini-0.4.11-py3-none-any.whl (8.4 kB)\n",
      "Using cached google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Using cached llama_index_core-0.12.23.post2-py3-none-any.whl (1.6 MB)\n",
      "Downloading pillow-10.4.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.6 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.6 MB 1.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.3/2.6 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.6/2.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 1.2 MB/s eta 0:00:00\n",
      "Using cached google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading google_api_python_client-2.164.0-py2.py3-none-any.whl (13.1 MB)\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.1 MB 2.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.0/13.1 MB 1.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/13.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.8/13.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/13.1 MB 1.8 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/13.1 MB 1.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.6/13.1 MB 667.1 kB/s eta 0:00:16\n",
      "   -------- ------------------------------- 2.6/13.1 MB 667.1 kB/s eta 0:00:16\n",
      "   -------- ------------------------------- 2.9/13.1 MB 655.8 kB/s eta 0:00:16\n",
      "   -------- ------------------------------- 2.9/13.1 MB 655.8 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 3.4/13.1 MB 706.3 kB/s eta 0:00:14\n",
      "   ------------ --------------------------- 3.9/13.1 MB 782.5 kB/s eta 0:00:12\n",
      "   ------------ --------------------------- 4.2/13.1 MB 813.7 kB/s eta 0:00:11\n",
      "   -------------- ------------------------- 4.7/13.1 MB 880.8 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 5.0/13.1 MB 901.0 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 5.5/13.1 MB 952.9 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.0/13.1 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 6.3/13.1 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 6.8/13.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 7.3/13.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 7.6/13.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.1/13.1 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 8.4/13.1 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 8.9/13.1 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 9.2/13.1 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 9.4/13.1 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 9.4/13.1 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 9.7/13.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.0/13.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 10.2/13.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 10.2/13.1 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 10.5/13.1 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 10.7/13.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 11.3/13.1 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.5/13.1 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 12.1/13.1 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.6/13.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/13.1 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.1/13.1 MB 1.3 MB/s eta 0:00:00\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, proto-plus, pillow, googleapis-common-protos, cachetools, rsa, pyasn1-modules, httplib2, grpcio-status, llama-index-core, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, llama-index-llms-gemini\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
      "Successfully installed cachetools-5.5.2 google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.164.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.4 googleapis-common-protos-1.69.1 grpcio-status-1.71.0 httplib2-0.22.0 llama-index-core-0.12.23.post2 llama-index-llms-gemini-0.4.11 pillow-10.4.0 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.1 rsa-4.9 uritemplate-4.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-vector-stores-qdrant 0.1.4 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.23.post2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama-index google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import pprint \n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader, \n",
    "    load_index_from_storage, \n",
    "    StorageContext, \n",
    "    ServiceContext,\n",
    "    Document\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentenceWindowNodeParser:\n",
    "Breaks down text into overlapping windows of sentences. Useful for capturing context within a larger text. Example: If the window size is 3, it would create nodes like: Sentence 1, Sentence 2, Sentence 3 Sentence 2, Sentence 3, Sentence 4 Sentence 3, Sentence 4, Sentence 5 2. HierarchicalNodeParser:\n",
    "\n",
    "Creates a hierarchical structure of nodes from text. Useful for organizing information into categories or subcategories. Example: A document with sections and subsections would be represented as a hierarchical structure. 3. get_leaf_nodes:\n",
    "\n",
    "A function that likely returns the leaf nodes from a hierarchical structure. Leaf nodes are the terminal nodes without children.\n",
    "\n",
    "Potential Use Cases: SentenceWindowNodeParser: For creating embeddings of text chunks with overlapping context. For building a search engine that can answer questions based on sentence-level context.\n",
    "\n",
    "HierarchicalNodeParser: For organizing large documents or datasets into a structured format. For creating a knowledge graph or ontology.\n",
    "\n",
    "get_leaf_nodes: For extracting the most granular information from a hierarchical structure. For performing specific operations on the lowest level nodes.\n",
    "\n",
    "Would you like to delve deeper into a specific class or use case? I can provide more detailed explanations or examples based on your requirements.\n",
    "\n",
    "Additionally, if you have a specific dataset or task in mind, I can help you determine the most suitable node parser and how to use it effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.text_splitter import SentenceSplitter \n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.schema import MetadataMode\n",
    "# MetadataMode is an enum defined in the llama index library to control how metadata is handled when interacting with documents or nodes. Essentially, it determines which metadata fields are included or excluded when preprocessing the data. \n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HiteshAnkodia1\\AppData\\Local\\llama_index\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Loading embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-mpnet-base-v2\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\demo projects\\advanced rag - sunny\\advanced-rag-11-sentence-window-rag\\venv\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyArxzKAiRsw6YaOr4hU8v0q6Yr1_5K-dJM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Verify if the key is loaded\n",
    "print(GOOGLE_API_KEY)  # Ensure it prints the key (or None if not found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "\n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenerateContent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msupported_generation_methods\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\generativeai\\models.py:202\u001b[39m, in \u001b[36mlist_models\u001b[39m\u001b[34m(page_size, client, request_options)\u001b[39m\n\u001b[32m    199\u001b[39m     request_options = {}\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     client = \u001b[43mget_default_model_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m client.list_models(page_size=page_size, **request_options):\n\u001b[32m    205\u001b[39m     model = \u001b[38;5;28mtype\u001b[39m(model).to_dict(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\generativeai\\client.py:372\u001b[39m, in \u001b[36mget_default_model_client\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_default_model_client\u001b[39m() -> glm.ModelServiceAsyncClient:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_client_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_client\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\generativeai\\client.py:289\u001b[39m, in \u001b[36m_ClientManager.get_default_client\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    287\u001b[39m client = \u001b[38;5;28mself\u001b[39m.clients.get(name)\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mself\u001b[39m.clients[name] = client\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\generativeai\\client.py:249\u001b[39m, in \u001b[36m_ClientManager.make_client\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ga_exceptions.DefaultCredentialsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    243\u001b[39m     e.args = (\n\u001b[32m    244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  No API_KEY or ADC found. Please either:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    - Set the `GOOGLE_API_KEY` environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    248\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_metadata:\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\generativeai\\client.py:241\u001b[39m, in \u001b[36m_ClientManager.make_client\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m patch_colab_gce_credentials():\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         client = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ga_exceptions.DefaultCredentialsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    243\u001b[39m     e.args = (\n\u001b[32m    244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  No API_KEY or ADC found. Please either:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    - Set the `GOOGLE_API_KEY` environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    248\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\model_service\\client.py:661\u001b[39m, in \u001b[36mModelServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    653\u001b[39m     transport_init: Union[\n\u001b[32m    654\u001b[39m         Type[ModelServiceTransport], Callable[..., ModelServiceTransport]\n\u001b[32m    655\u001b[39m     ] = (\n\u001b[32m   (...)\u001b[39m\u001b[32m    658\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., ModelServiceTransport], transport)\n\u001b[32m    659\u001b[39m     )\n\u001b[32m    660\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    674\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    675\u001b[39m         std_logging.DEBUG\n\u001b[32m    676\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\model_service\\transports\\grpc.py:239\u001b[39m, in \u001b[36mModelServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    234\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    235\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    236\u001b[39m             )\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    251\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    252\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\model_service\\transports\\base.py:103\u001b[39m, in \u001b[36mModelServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m    100\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m    101\u001b[39m     )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\google\\auth\\_default.py:719\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    711\u001b[39m             _LOGGER.warning(\n\u001b[32m    712\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    713\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    714\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    715\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    716\u001b[39m             )\n\u001b[32m    717\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information."
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "llm = Gemini(\n",
    "    model=\"models/gemini-1.5-flash\",\n",
    "    # api_key=\"some key\",  # uses GOOGLE_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hello friend!  How are you doing today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"Hello friend!\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ./my_data/teahistory.txt\n",
      "Downloaded: ./my_data/chinahistory.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\"./my_data\", exist_ok=True)\n",
    "\n",
    "# Function to download a file\n",
    "def download_file(url, save_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {url}\")\n",
    "\n",
    "# URLs\n",
    "tea_history_url = \"https://www.gutenberg.org/cache/epub/72306/pg72306.txt\"\n",
    "china_history_url = \"https://www.gutenberg.org/cache/epub/11367/pg11367.txt\"\n",
    "\n",
    "# Save paths\n",
    "tea_history_path = \"./my_data/teahistory.txt\"\n",
    "china_history_path = \"./my_data/chinahistory.txt\"\n",
    "\n",
    "# Download files\n",
    "download_file(tea_history_url, tea_history_path)\n",
    "download_file(china_history_url, china_history_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of doc: 1\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(input_files=[\"my_data/chinahistory.txt\"]).load_data()\n",
    "# Inspect the documents\n",
    "print(\"length of doc: \"+ str(len(documents)))\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'my_data\\\\chinahistory.txt',\n",
       " 'file_name': 'chinahistory.txt',\n",
       " 'file_type': 'text/plain',\n",
       " 'file_size': 977333,\n",
       " 'creation_date': '2025-03-13',\n",
       " 'last_modified_date': '2025-03-13'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Node Parser in LlamaIndex is responsible for breaking down documents into smaller, manageable units called nodes.\n",
    "\n",
    "Think of a document as a large book. A node parser is like a chapter divider or even a sentence splitter, depending on how granular you want to go.\n",
    "\n",
    "Key Functions of a Node Parser: Chunking: Divides documents into smaller pieces. Metadata Extraction: Can extract relevant metadata from the document for each node. Structure Preservation: Some node parsers can maintain the original structure of the document (e.g., hierarchical structure).\n",
    "\n",
    "Breakdown of the Code The code snippet you provided creates a SentenceWindowNodeParser instance using the from_defaults method. This method is likely a convenience function to create a parser with common default settings.\n",
    "\n",
    "Let's break down the parameters:\n",
    "\n",
    "window_size=3: This sets the size of the sliding window used to create sentence-based nodes. In this case, each node will contain three consecutive sentences. window_metadata_key=\"window\": This specifies the metadata key to use for storing the actual window content within the node. original_text_metadata_key=\"original_text\": This specifies the metadata key to store the original text from which the window was extracted. What it Does This code creates a parser that will:\n",
    "\n",
    "Split the input text into sentences. Create overlapping windows of three sentences each. Create nodes for each window, storing the window content under the \"window\" metadata key and the original text under the \"original_text\" metadata key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement llama_index.node_parser (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for llama_index.node_parser\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index.node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sentence window node parser w/ default settings\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "sentence_node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = sentence_node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "#Normal Text Spiltter \n",
    "base_node_parser = SentenceSplitter()\n",
    "base_nodes = base_node_parser.get_nodes_from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7014"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import Settings \n",
    "#This will set the vairables in enviornment. \n",
    "Settings.llm = llm \n",
    "Settings.embed_model = embed_model \n",
    "Settings.text_splitter = base_node_parser\n",
    "\n",
    "# Normal Sentence Splitter.\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentenceWindowNodeParser Text Splitter \n",
    "len(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of such\n",
      "adjustments are as follows:\n",
      "\n",
      "  From                        To\n",
      "Northwestern             North-western\n",
      "Southwards               Southward\n",
      "Programme                Program\n",
      "re-introduced            reintroduced\n",
      "practise                 practice\n",
      "Lotos                    Lotus\n",
      "Ju-Chn                  Juchn\n",
      "cooperate                co-operate\n",
      "life-time                lifetime\n",
      "man-power                manpower\n",
      "favor                    favour\n",
      "etc.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nodes[7].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This burial custom, which is found among primitive peoples in\n",
      "other parts of the world, suggests the conclusion that the Peking Man\n",
      "already had religious notions. We have no knowledge yet of the length of\n",
      "time the Peking Man may have inhabited the Far East. His first traces\n",
      "are attributed to a million years ago, and he may have flourished in\n",
      "500,000 B.C.\n",
      "\n",
      "3 _The Palaeolithic Age_\n",
      "\n",
      "After the period of the Peking Man there comes a great gap in our\n",
      "knowledge. All that we know indicates that at the time of the Peking Man\n",
      "there must have been a warmer and especially a damper climate in North\n",
      "China and Inner Mongolia than today. Great areas of the Ordos region,\n",
      "now dry steppe, were traversed in that epoch by small rivers and lakes\n",
      "beside which men could live. There were elephants, rhinoceroses, extinct\n",
      "species of stag and bull, even tapirs and other wild animals. About\n",
      "50,000 B.C. there lived by these lakes a hunting people whose stone\n",
      "implements (and a few of bone) have been found in many places. The\n",
      "implements are comparable in type with the palaeolithic implements of\n",
      "Europe (Mousterian type, and more rarely Aurignacian or even\n",
      "Magdalenian). They are not, however, exactly like the European\n",
      "implements, but have a character of their own. We do not yet know what\n",
      "the men of these communities looked like, because as yet no indisputable\n",
      "human remains have been found. All the stone implements have been found\n",
      "on the surface, where they have been brought to light by the wind as it\n",
      "swept away the loess. These stone-age communities seem to have lasted a\n",
      "considerable time and to have been spread not only over North China but\n",
      "over Mongolia and Manchuria. It must not be assumed that the stone age\n",
      "came to an end at the same time everywhere. Historical accounts have\n",
      "recorded, for instance, that stone implements were still in use in\n",
      "Manchuria and eastern Mongolia at a time when metal was known and used\n",
      "in western Mongolia and northern China. Our knowledge about the\n",
      "palaeolithic period of Central and South China is still extremely\n",
      "limited; we have to wait for more excavations before anything can be\n",
      "said. Certainly, many implements in this area were made of wood or more\n",
      "probably bamboo, such as we still find among the non-Chinese tribes of\n",
      "the south-west and of South-East Asia. Such implements, naturally, could\n",
      "not last until today.\n",
      "\n",
      "About 25,000 B.C. there appears in North China a new human type, found\n",
      "in upper layers in the same caves that sheltered Peking Man. This type\n",
      "is beyond doubt not Mongoloid, and may have been allied to the Ainu, a\n",
      "non-Mongol race still living in northern Japan. These, too, were a\n",
      "palaeolithic people, though some of their implements show technical\n",
      "advance. Later they disappear, probably because they were absorbed into\n",
      "various populations of central and northern Asia. Remains of them have\n",
      "been found in badly explored graves in northern Korea.\n",
      "\n",
      "4 _The Neolithic age_\n",
      "\n",
      "In the period that now followed, northern China must have gradually\n",
      "become arid, and the formation of loess seems to have steadily advanced.\n",
      "There is once more a great gap in our knowledge until, about 4000 B.C.,\n",
      "we can trace in North China a purely Mongoloid people with a neolithic\n",
      "culture. In place of hunters we find cattle breeders, who are even to\n",
      "some extent agriculturists as well. This may seem an astonishing\n",
      "statement for so early an age. It is a fact, however, that pure pastoral\n",
      "nomadism is exceptional, that normal pastoral nomads have always added a\n",
      "little farming to their cattle-breeding, in order to secure the needed\n",
      "additional food and above all fodder, for the winter.\n",
      "\n",
      "At this time, about 4000 B.C., the other parts of China come into view.\n",
      "The neolithic implements of the various regions of the Far East are far\n",
      "from being uniform; there are various separate cultures. In the\n",
      "north-west of China there is a system of cattle-breeding combined with\n",
      "agriculture, a distinguishing feature being the possession of finely\n",
      "polished axes of rectangular section, with a cutting edge. Farther east,\n",
      "in the north and reaching far to the south, is found a culture with axes\n",
      "of round or oval section.\n"
     ]
    }
   ],
   "source": [
    "print(base_nodes[7].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '5777ee1f-97a1-4572-845e-a3a488084684',\n",
       " 'embedding': None,\n",
       " 'metadata': {'file_path': 'my_data\\\\chinahistory.txt',\n",
       "  'file_name': 'chinahistory.txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 977333,\n",
       "  'creation_date': '2025-03-13',\n",
       "  'last_modified_date': '2025-03-13',\n",
       "  'window': \"Characters accented by those marks, and the corresponding text\\r\\nrepresentations are as follows (where x represents the character being\\r\\naccented).  All such symbols in this text above the character being\\r\\naccented:\\r\\n\\r\\n  breve (u-shaped symbol):  [)x]\\r\\n  caron (v-shaped symbol):  [vx]\\r\\n  macron (straight line):   [=x]\\r\\n  acute (gu) accent:       ['x]\\r\\n\\r\\nAdditionally, the author has spelled certain words inconsistently.  Those\\r\\nhave been adjusted to be consistent where possible.  Examples of such\\r\\nadjustments are as follows:\\r\\n\\r\\n  From                        To\\r\\nNorthwestern             North-western\\r\\nSouthwards               Southward\\r\\nProgramme                Program\\r\\nre-introduced            reintroduced\\r\\npractise                 practice\\r\\nLotos                    Lotus\\r\\nJu-Chn                  Juchn\\r\\ncooperate                co-operate\\r\\nlife-time                lifetime\\r\\nman-power                manpower\\r\\nfavor                    favour\\r\\netc.\\r\\n\\r\\n In general such changes are made to be consistent with the predominate\\r\\nusage in the text, or if there was not a predominate spelling, to the\\r\\nmore modern.]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n A HISTORY OF CHINA\\r\\n\\r\\nby\\r\\n\\r\\nWOLFRAM EBERHARD\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCONTENTS\\r\\n\\r\\nINTRODUCTION\\r\\n\\r\\n\\r\\n           _THE EARLIEST TIMES_\\r\\n\\r\\nChapter I: PREHISTORY\\r\\n\\r\\n  1 Sources for the earliest history\\r\\n  2 The Peking Man\\r\\n  3 The Palaeolithic Age\\r\\n  4 The Neolithic Age\\r\\n  5 The eight principal prehistoric cultures\\r\\n  6 The Yang-shao culture\\r\\n  7 The Lung-shan culture\\r\\n  8 The first petty States in Shansi\\r\\n\\r\\nChapter II: THE SHANG DYNASTY (_c_.  1600-1028 B.C.)\\r\\n\\r\\n  \",\n",
       "  'original_text': 'Examples of such\\r\\nadjustments are as follows:\\r\\n\\r\\n  From                        To\\r\\nNorthwestern             North-western\\r\\nSouthwards               Southward\\r\\nProgramme                Program\\r\\nre-introduced            reintroduced\\r\\npractise                 practice\\r\\nLotos                    Lotus\\r\\nJu-Chn                  Juchn\\r\\ncooperate                co-operate\\r\\nlife-time                lifetime\\r\\nman-power                manpower\\r\\nfavor                    favour\\r\\netc.\\r\\n\\r\\n'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date',\n",
       "  'window',\n",
       "  'original_text'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date',\n",
       "  'window',\n",
       "  'original_text'],\n",
       " 'relationships': {<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='da0ac287-b130-4459-b176-79f1379df0a6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'my_data\\\\chinahistory.txt', 'file_name': 'chinahistory.txt', 'file_type': 'text/plain', 'file_size': 977333, 'creation_date': '2025-03-13', 'last_modified_date': '2025-03-13'}, hash='8981d9a722c972b3afe0ebc0223bcdf81cad57cbb8e3d93ab2b12584bb8130e2'),\n",
       "  <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='48dc8b96-b037-45d2-9e67-b67f4eb3c633', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'my_data\\\\chinahistory.txt', 'file_name': 'chinahistory.txt', 'file_type': 'text/plain', 'file_size': 977333, 'creation_date': '2025-03-13', 'last_modified_date': '2025-03-13', 'window': \"Title: A History of China\\r\\n\\r\\nAuthor: Wolfram Eberhard\\r\\n\\r\\nRelease date: February 1, 2004 [eBook #11367]\\r\\n                Most recently updated: December 25, 2020\\r\\n\\r\\nLanguage: English\\r\\n\\r\\nCredits: Produced by Juliet Sutherland, Gene Smethers and PG Distributed Proofreaders\\r\\n\\r\\n\\r\\n*** START OF THE PROJECT GUTENBERG EBOOK A HISTORY OF CHINA ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nProduced by Juliet Sutherland, Gene Smethers and PG Distributed\\r\\nProofreaders\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n[Transcriber's Note: The following text contains numerous non-English\\r\\nwords containing diacritical marks not contained in the ASCII character\\r\\nset.  Characters accented by those marks, and the corresponding text\\r\\nrepresentations are as follows (where x represents the character being\\r\\naccented).  All such symbols in this text above the character being\\r\\naccented:\\r\\n\\r\\n  breve (u-shaped symbol):  [)x]\\r\\n  caron (v-shaped symbol):  [vx]\\r\\n  macron (straight line):   [=x]\\r\\n  acute (gu) accent:       ['x]\\r\\n\\r\\nAdditionally, the author has spelled certain words inconsistently.  Those\\r\\nhave been adjusted to be consistent where possible.  Examples of such\\r\\nadjustments are as follows:\\r\\n\\r\\n  From                        To\\r\\nNorthwestern             North-western\\r\\nSouthwards               Southward\\r\\nProgramme                Program\\r\\nre-introduced            reintroduced\\r\\npractise                 practice\\r\\nLotos                    Lotus\\r\\nJu-Chn                  Juchn\\r\\ncooperate                co-operate\\r\\nlife-time                lifetime\\r\\nman-power                manpower\\r\\nfavor                    favour\\r\\netc.\\r\\n\\r\\n In general such changes are made to be consistent with the predominate\\r\\nusage in the text, or if there was not a predominate spelling, to the\\r\\nmore modern.]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n A HISTORY OF CHINA\\r\\n\\r\\nby\\r\\n\\r\\nWOLFRAM EBERHARD\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCONTENTS\\r\\n\\r\\nINTRODUCTION\\r\\n\\r\\n\\r\\n           _THE EARLIEST TIMES_\\r\\n\\r\\nChapter I: PREHISTORY\\r\\n\\r\\n  1 Sources for the earliest history\\r\\n  2 The Peking Man\\r\\n  3 The Palaeolithic Age\\r\\n  4 The Neolithic Age\\r\\n  5 The eight principal prehistoric cultures\\r\\n  6 The Yang-shao culture\\r\\n  7 The Lung-shan culture\\r\\n  8 The first petty States in Shansi\\r\\n\\r\\nChapter II: THE SHANG DYNASTY (_c_. \", 'original_text': 'Those\\r\\nhave been adjusted to be consistent where possible. '}, hash='dfff9b0c6b333c68e87a95e3aeaaf8dc47c1f77f8a5311f272f1d6900efef143'),\n",
       "  <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a55ac6b9-ea9a-4dcb-9b60-c7b16b3e5e42', node_type=<ObjectType.TEXT: '1'>, metadata={'window': \"All such symbols in this text above the character being\\r\\naccented:\\r\\n\\r\\n  breve (u-shaped symbol):  [)x]\\r\\n  caron (v-shaped symbol):  [vx]\\r\\n  macron (straight line):   [=x]\\r\\n  acute (gu) accent:       ['x]\\r\\n\\r\\nAdditionally, the author has spelled certain words inconsistently.  Those\\r\\nhave been adjusted to be consistent where possible.  Examples of such\\r\\nadjustments are as follows:\\r\\n\\r\\n  From                        To\\r\\nNorthwestern             North-western\\r\\nSouthwards               Southward\\r\\nProgramme                Program\\r\\nre-introduced            reintroduced\\r\\npractise                 practice\\r\\nLotos                    Lotus\\r\\nJu-Chn                  Juchn\\r\\ncooperate                co-operate\\r\\nlife-time                lifetime\\r\\nman-power                manpower\\r\\nfavor                    favour\\r\\netc.\\r\\n\\r\\n In general such changes are made to be consistent with the predominate\\r\\nusage in the text, or if there was not a predominate spelling, to the\\r\\nmore modern.]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n A HISTORY OF CHINA\\r\\n\\r\\nby\\r\\n\\r\\nWOLFRAM EBERHARD\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCONTENTS\\r\\n\\r\\nINTRODUCTION\\r\\n\\r\\n\\r\\n           _THE EARLIEST TIMES_\\r\\n\\r\\nChapter I: PREHISTORY\\r\\n\\r\\n  1 Sources for the earliest history\\r\\n  2 The Peking Man\\r\\n  3 The Palaeolithic Age\\r\\n  4 The Neolithic Age\\r\\n  5 The eight principal prehistoric cultures\\r\\n  6 The Yang-shao culture\\r\\n  7 The Lung-shan culture\\r\\n  8 The first petty States in Shansi\\r\\n\\r\\nChapter II: THE SHANG DYNASTY (_c_.  1600-1028 B.C.)\\r\\n\\r\\n   1 Period, origin, material culture\\r\\n  2 Writing and Religion\\r\\n  3 Transition to feudalism\\r\\n\\r\\n\\r\\n             _ANTIQUITY_\\r\\n\\r\\nChapter III: THE CHOU DYNASTY (_c_. \", 'original_text': 'In general such changes are made to be consistent with the predominate\\r\\nusage in the text, or if there was not a predominate spelling, to the\\r\\nmore modern.]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n'}, hash='82915089b80663f7c005a57a4d6a4dd11ba22fc4c94084f95b8d1277909fb5de')},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text': 'Examples of such\\r\\nadjustments are as follows:\\r\\n\\r\\n  From                        To\\r\\nNorthwestern             North-western\\r\\nSouthwards               Southward\\r\\nProgramme                Program\\r\\nre-introduced            reintroduced\\r\\npractise                 practice\\r\\nLotos                    Lotus\\r\\nJu-Chn                  Juchn\\r\\ncooperate                co-operate\\r\\nlife-time                lifetime\\r\\nman-power                manpower\\r\\nfavor                    favour\\r\\netc.\\r\\n\\r\\n',\n",
       " 'mimetype': 'text/plain',\n",
       " 'start_char_idx': 1578,\n",
       " 'end_char_idx': 2058,\n",
       " 'metadata_seperator': '\\n',\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(nodes[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '22fa16a0-8134-407e-ba47-af4b723ccd76',\n",
       " 'embedding': None,\n",
       " 'metadata': {'file_path': 'my_data\\\\chinahistory.txt',\n",
       "  'file_name': 'chinahistory.txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 977333,\n",
       "  'creation_date': '2025-03-13',\n",
       "  'last_modified_date': '2025-03-13'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='da0ac287-b130-4459-b176-79f1379df0a6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'my_data\\\\chinahistory.txt', 'file_name': 'chinahistory.txt', 'file_type': 'text/plain', 'file_size': 977333, 'creation_date': '2025-03-13', 'last_modified_date': '2025-03-13'}, hash='8981d9a722c972b3afe0ebc0223bcdf81cad57cbb8e3d93ab2b12584bb8130e2'),\n",
       "  <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1d84c922-797d-4a7e-9f96-5ab23b963a94', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'my_data\\\\chinahistory.txt', 'file_name': 'chinahistory.txt', 'file_type': 'text/plain', 'file_size': 977333, 'creation_date': '2025-03-13', 'last_modified_date': '2025-03-13'}, hash='4a39b3057e10c86e1e3e47a87a98a59ac3b8f32b5582179025e1ace70efea335'),\n",
       "  <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='22be2222-0b4e-4fe9-aa4c-8e53768eadd2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='401a4044c15e065c4ff825b0dfde4fdd84e94a9e460e45865733476dccdfc22b')},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text': 'This burial custom, which is found among primitive peoples in\\r\\nother parts of the world, suggests the conclusion that the Peking Man\\r\\nalready had religious notions. We have no knowledge yet of the length of\\r\\ntime the Peking Man may have inhabited the Far East. His first traces\\r\\nare attributed to a million years ago, and he may have flourished in\\r\\n500,000 B.C.\\r\\n\\r\\n3 _The Palaeolithic Age_\\r\\n\\r\\nAfter the period of the Peking Man there comes a great gap in our\\r\\nknowledge. All that we know indicates that at the time of the Peking Man\\r\\nthere must have been a warmer and especially a damper climate in North\\r\\nChina and Inner Mongolia than today. Great areas of the Ordos region,\\r\\nnow dry steppe, were traversed in that epoch by small rivers and lakes\\r\\nbeside which men could live. There were elephants, rhinoceroses, extinct\\r\\nspecies of stag and bull, even tapirs and other wild animals. About\\r\\n50,000 B.C. there lived by these lakes a hunting people whose stone\\r\\nimplements (and a few of bone) have been found in many places. The\\r\\nimplements are comparable in type with the palaeolithic implements of\\r\\nEurope (Mousterian type, and more rarely Aurignacian or even\\r\\nMagdalenian). They are not, however, exactly like the European\\r\\nimplements, but have a character of their own. We do not yet know what\\r\\nthe men of these communities looked like, because as yet no indisputable\\r\\nhuman remains have been found. All the stone implements have been found\\r\\non the surface, where they have been brought to light by the wind as it\\r\\nswept away the loess. These stone-age communities seem to have lasted a\\r\\nconsiderable time and to have been spread not only over North China but\\r\\nover Mongolia and Manchuria. It must not be assumed that the stone age\\r\\ncame to an end at the same time everywhere. Historical accounts have\\r\\nrecorded, for instance, that stone implements were still in use in\\r\\nManchuria and eastern Mongolia at a time when metal was known and used\\r\\nin western Mongolia and northern China. Our knowledge about the\\r\\npalaeolithic period of Central and South China is still extremely\\r\\nlimited; we have to wait for more excavations before anything can be\\r\\nsaid. Certainly, many implements in this area were made of wood or more\\r\\nprobably bamboo, such as we still find among the non-Chinese tribes of\\r\\nthe south-west and of South-East Asia. Such implements, naturally, could\\r\\nnot last until today.\\r\\n\\r\\nAbout 25,000 B.C. there appears in North China a new human type, found\\r\\nin upper layers in the same caves that sheltered Peking Man. This type\\r\\nis beyond doubt not Mongoloid, and may have been allied to the Ainu, a\\r\\nnon-Mongol race still living in northern Japan. These, too, were a\\r\\npalaeolithic people, though some of their implements show technical\\r\\nadvance. Later they disappear, probably because they were absorbed into\\r\\nvarious populations of central and northern Asia. Remains of them have\\r\\nbeen found in badly explored graves in northern Korea.\\r\\n\\r\\n4 _The Neolithic age_\\r\\n\\r\\nIn the period that now followed, northern China must have gradually\\r\\nbecome arid, and the formation of loess seems to have steadily advanced.\\r\\nThere is once more a great gap in our knowledge until, about 4000 B.C.,\\r\\nwe can trace in North China a purely Mongoloid people with a neolithic\\r\\nculture. In place of hunters we find cattle breeders, who are even to\\r\\nsome extent agriculturists as well. This may seem an astonishing\\r\\nstatement for so early an age. It is a fact, however, that pure pastoral\\r\\nnomadism is exceptional, that normal pastoral nomads have always added a\\r\\nlittle farming to their cattle-breeding, in order to secure the needed\\r\\nadditional food and above all fodder, for the winter.\\r\\n\\r\\nAt this time, about 4000 B.C., the other parts of China come into view.\\r\\nThe neolithic implements of the various regions of the Far East are far\\r\\nfrom being uniform; there are various separate cultures. In the\\r\\nnorth-west of China there is a system of cattle-breeding combined with\\r\\nagriculture, a distinguishing feature being the possession of finely\\r\\npolished axes of rectangular section, with a cutting edge. Farther east,\\r\\nin the north and reaching far to the south, is found a culture with axes\\r\\nof round or oval section.',\n",
       " 'mimetype': 'text/plain',\n",
       " 'start_char_idx': 23999,\n",
       " 'end_char_idx': 28200,\n",
       " 'metadata_seperator': '\\n',\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(base_nodes[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_sentence = {\n",
    "    \"llm\": Settings.llm,\n",
    "    \"embed_model\": Settings.embed_model,\n",
    "    \"node_parser\": sentence_node_parser,\n",
    "}\n",
    "\n",
    "ctx_base = {\n",
    "    \"llm\": Settings.llm,\n",
    "    \"embed_model\": Settings.embed_model,\n",
    "    \"node_parser\": base_node_parser,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import qdrant_client\n",
    "client = qdrant_client.QdrantClient(\n",
    "    \"https://e49c847b-1f89-48a4-9e0c-38f2f41489c0.eu-central-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.JNi4YQ8LsYsk4M2wrz7F33ZTG4iby--_voaa0vdERY0\", # For Qdrant Cloud, None for local instance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `sample-custer` already exists!\"},\"time\":0.02299944}'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedResponse\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m distance_metric = \u001b[33m\"\u001b[39m\u001b[33mCosine\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Can be \"Cosine\", \"Euclidean\", \"Dot\" depending on the distance measure you prefer\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Create the collection\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVectorParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollection \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has been created!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:2236\u001b[39m, in \u001b[36mQdrantClient.create_collection\u001b[39m\u001b[34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, **kwargs)\u001b[39m\n\u001b[32m   2187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create empty collection with given parameters\u001b[39;00m\n\u001b[32m   2188\u001b[39m \n\u001b[32m   2189\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2232\u001b[39m \u001b[33;03m    Operation result\u001b[39;00m\n\u001b[32m   2233\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2234\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) == \u001b[32m0\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_number\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshard_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m    \u001b[49m\u001b[43msharding_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharding_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwal_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwal_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2251\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2252\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py:2821\u001b[39m, in \u001b[36mQdrantRemote.create_collection\u001b[39m\u001b[34m(self, collection_name, vectors_config, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, sparse_vectors_config, sharding_method, **kwargs)\u001b[39m\n\u001b[32m   2804\u001b[39m     init_from = GrpcToRest.convert_init_from(init_from)\n\u001b[32m   2806\u001b[39m create_collection_request = models.CreateCollection(\n\u001b[32m   2807\u001b[39m     vectors=vectors_config,\n\u001b[32m   2808\u001b[39m     shard_number=shard_number,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2818\u001b[39m     sharding_method=sharding_method,\n\u001b[32m   2819\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2821\u001b[39m result: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_collection_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m   2827\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mCreate collection returned None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:1170\u001b[39m, in \u001b[36mSyncCollectionsApi.create_collection\u001b[39m\u001b[34m(self, collection_name, timeout, create_collection)\u001b[39m\n\u001b[32m   1161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_collection\u001b[39m(\n\u001b[32m   1162\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1163\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   1164\u001b[39m     timeout: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1165\u001b[39m     create_collection: m.CreateCollection = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1166\u001b[39m ) -> m.InlineResponse200:\n\u001b[32m   1167\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[33;03m    Create new collection with given parameters\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_for_create_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:116\u001b[39m, in \u001b[36m_CollectionsApi._build_for_create_collection\u001b[39m\u001b[34m(self, collection_name, timeout, create_collection)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[32m    115\u001b[39m     headers[\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInlineResponse200\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:79\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, type_, method, url, path_params, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m request = \u001b[38;5;28mself\u001b[39m._client.build_request(method, url, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:102\u001b[39m, in \u001b[36mApiClient.send\u001b[39m\u001b[34m(self, request, type_)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    101\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse.for_response(response)\n",
      "\u001b[31mUnexpectedResponse\u001b[39m: Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `sample-custer` already exists!\"},\"time\":0.02299944}'"
     ]
    }
   ],
   "source": [
    "\n",
    "from qdrant_client.models import  VectorParams\n",
    "\n",
    "# Define the collection name and vector configuration\n",
    "collection_name = \"sample-custer\"  # Your collection name\n",
    "vector_size = 128  # Adjust the size of your vectors (it must match the size of the vectors you're storing)\n",
    "distance_metric = \"Cosine\"  # Can be \"Cosine\", \"Euclidean\", \"Dot\" depending on the distance measure you prefer\n",
    "\n",
    "# Create the collection\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=vector_size, distance=distance_metric)\n",
    ")\n",
    "\n",
    "print(f\"Collection '{collection_name}' has been created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_fields' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vector_store = \u001b[43mQdrantVectorStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msample-custer\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\llama_index\\vector_stores\\qdrant\\base.py:141\u001b[39m, in \u001b[36mQdrantVectorStore.__init__\u001b[39m\u001b[34m(self, collection_name, client, aclient, url, api_key, batch_size, parallel, max_retries, client_kwargs, enable_hybrid, sparse_doc_fn, sparse_query_fn, hybrid_fusion_fn, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m aclient \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    136\u001b[39m         logger.warning(\n\u001b[32m    137\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mBoth client and aclient are provided. If using `:memory:` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmode, the data between clients is not synced.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m = client\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mself\u001b[39m._aclient = aclient\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Demo Projects\\Advanced RAG - Sunny\\Advanced-RAG-11-Sentence-window-rag\\venv\\Lib\\site-packages\\pydantic\\main.py:899\u001b[39m, in \u001b[36m__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mNameError\u001b[39m: name '_fields' is not defined"
     ]
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(client=client, collection_name = 'sample-custer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents,storage_context=storage_context,service_context=ctx_sentence)\n",
    "vector_store2 = QdrantVectorStore(client=client, collection_name=\"got_base_node\")\n",
    "storage_context2 = StorageContext.from_defaults(vector_store=vector_store2)\n",
    "index2 = VectorStoreIndex.from_documents(documents,storage_context=storage_context2,service_context=ctx_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Query Engine\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "sentence_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    verbose=True,\n",
    "    # the target key defaults to `window` to match the node_parser's default\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Query Engine.\n",
    "base_query_engine = index2.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How long have Gared and Will been part of the Night's Watch?\"\n",
    "\n",
    "\n",
    "base_response = base_query_engine.query(\n",
    "    question\n",
    ")\n",
    "print(base_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence_response = sentence_query_engine.query(\n",
    "    question\n",
    ")\n",
    "print(sentence_response)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
